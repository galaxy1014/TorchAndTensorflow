{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "(x_train,y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test / 255.0\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002CC9E9651F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002CC9E9651F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1851/1875 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.9124WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002CCA3893288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002CCA3893288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3041 - accuracy: 0.9128 - val_loss: 0.1781 - val_accuracy: 0.9484\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 2s 949us/step - loss: 0.1504 - accuracy: 0.9557 - val_loss: 0.1321 - val_accuracy: 0.9618\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 2s 980us/step - loss: 0.1092 - accuracy: 0.9670 - val_loss: 0.1073 - val_accuracy: 0.9683\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 2s 942us/step - loss: 0.0861 - accuracy: 0.9742 - val_loss: 0.1052 - val_accuracy: 0.9681\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 2s 942us/step - loss: 0.0715 - accuracy: 0.9784 - val_loss: 0.0952 - val_accuracy: 0.9702\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.0595 - accuracy: 0.9819 - val_loss: 0.0943 - val_accuracy: 0.9726\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 2s 967us/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.0893 - val_accuracy: 0.9729\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 2s 949us/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 2s 979us/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.0927 - val_accuracy: 0.9728\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0930 - val_accuracy: 0.9730\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.0993 - val_accuracy: 0.9721\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0931 - val_accuracy: 0.9734\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 2s 954us/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.1027 - val_accuracy: 0.9717\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 2s 962us/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0969 - val_accuracy: 0.9752\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1216 - val_accuracy: 0.9687\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 2s 942us/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.1050 - val_accuracy: 0.9745\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.1073 - val_accuracy: 0.9728\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 2s 989us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.1156 - val_accuracy: 0.9719\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 2s 952us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1203 - val_accuracy: 0.9731\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 2s 954us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1166 - val_accuracy: 0.9732\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1172 - val_accuracy: 0.9732\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1205 - val_accuracy: 0.9732\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1235 - val_accuracy: 0.9726\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 2s 999us/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1427 - val_accuracy: 0.9726\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 2s 954us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1335 - val_accuracy: 0.9747\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1402 - val_accuracy: 0.9735\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 2s 985us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1271 - val_accuracy: 0.9759\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1447 - val_accuracy: 0.9739\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 2s 948us/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1431 - val_accuracy: 0.9712\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 2s 990us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1433 - val_accuracy: 0.9719\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1441 - val_accuracy: 0.9728\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 2s 962us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1552 - val_accuracy: 0.9735\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1545 - val_accuracy: 0.9732\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 2s 967us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1558 - val_accuracy: 0.9721\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 2s 982us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1673 - val_accuracy: 0.9719\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1700 - val_accuracy: 0.9725\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 2s 998us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1695 - val_accuracy: 0.9742\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 2s 972us/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1583 - val_accuracy: 0.9747\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 2s 983us/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1653 - val_accuracy: 0.9734\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 2s 948us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1814 - val_accuracy: 0.9723\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 2s 956us/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1616 - val_accuracy: 0.9755\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 2s 1000us/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1684 - val_accuracy: 0.9739\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1722 - val_accuracy: 0.9737\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1797 - val_accuracy: 0.9732\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 2s 987us/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.1735 - val_accuracy: 0.9737\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 2s 941us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.1803 - val_accuracy: 0.9745\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.4081e-04 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9750\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 2s 993us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1823 - val_accuracy: 0.9729\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1943 - val_accuracy: 0.9727\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1921 - val_accuracy: 0.9733\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 2s 975us/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1818 - val_accuracy: 0.9733\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1873 - val_accuracy: 0.9736\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 2s 964us/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1861 - val_accuracy: 0.9748\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 2s 994us/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1911 - val_accuracy: 0.9742\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 2s 976us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.2012 - val_accuracy: 0.9736\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 2s 941us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1847 - val_accuracy: 0.9740\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1990 - val_accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 2s 958us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1970 - val_accuracy: 0.9736\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.2058 - val_accuracy: 0.9725\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 2s 999us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2347 - val_accuracy: 0.9679\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 2s 958us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.2087 - val_accuracy: 0.9734\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.2058 - val_accuracy: 0.9742\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.2362 - val_accuracy: 0.9710\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 2s 981us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2239 - val_accuracy: 0.9723\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 2s 981us/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2110 - val_accuracy: 0.9751\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2186 - val_accuracy: 0.9726\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 2s 962us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.2259 - val_accuracy: 0.9718\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 2s 974us/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.2245 - val_accuracy: 0.9735\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.6682e-04 - accuracy: 0.9999 - val_loss: 0.2121 - val_accuracy: 0.9740\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 6.4701e-05 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9746\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 2s 956us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2225 - val_accuracy: 0.9731\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 2s 991us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.2289 - val_accuracy: 0.9741\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 2s 963us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.2393 - val_accuracy: 0.9737\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.2161 - val_accuracy: 0.9732\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2561 - val_accuracy: 0.9737\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 2s 964us/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2195 - val_accuracy: 0.9744\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 2s 965us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.2319 - val_accuracy: 0.9747\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2306 - val_accuracy: 0.9744\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 2s 973us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.2277 - val_accuracy: 0.9729\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 2s 968us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2397 - val_accuracy: 0.9734\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2342 - val_accuracy: 0.9737\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2251 - val_accuracy: 0.9755\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 2s 950us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2584 - val_accuracy: 0.9724\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.2433 - val_accuracy: 0.9737\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 2s 980us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2255 - val_accuracy: 0.9753\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 2s 966us/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.2296 - val_accuracy: 0.9746\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 2s 994us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2393 - val_accuracy: 0.9748\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2463 - val_accuracy: 0.9748\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 2s 956us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.2608 - val_accuracy: 0.9723\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 2s 985us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2409 - val_accuracy: 0.9748\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 2s 942us/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.2500 - val_accuracy: 0.9737\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 2s 953us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.2430 - val_accuracy: 0.9742\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 2s 997us/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2334 - val_accuracy: 0.9744\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 2s 942us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2751 - val_accuracy: 0.9714\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 2s 952us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2432 - val_accuracy: 0.9748\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 2s 996us/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.2485 - val_accuracy: 0.9749\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.2415 - val_accuracy: 0.9746\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2549 - val_accuracy: 0.9748\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 2s 976us/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2665 - val_accuracy: 0.9724\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2476 - val_accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc9e95dac8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.2476 - accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24759164452552795, 0.9747999906539917]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4cad6b2b944dc2837f99dd6e6394cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dda7f5cf9d4a3d818ffdcce298e4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab68bf0f3f4f406bb0c6a7880f8ef745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c589e836cca46ccb1b90e61f33074b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST_DATA\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "directory = './MNIST_DATA'\n",
    "train_dataset = MNIST(directory, transform=transforms.ToTensor(), train=True, \n",
    "                     download=True)\n",
    "test_dataset = MNIST(directory, transform=transforms.ToTensor(), train=False,\n",
    "                    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                         shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
    "                        , drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnist, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 64).to('cuda:0'),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10).to('cuda:0'),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist()\n",
    "criterion = nn.CrossEntropyLoss().to('cuda:0')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(101):    \n",
    "    for X, Y in train_loader:\n",
    "        X = X.view(-1, 28 * 28).to('cuda:0')\n",
    "        Y = Y.to('cuda:0')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Accuracy: 0.9266999959945679\n",
      "Label:  8\n",
      "Prediction:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or7l0\\anaconda3\\envs\\ju_hoon\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\or7l0\\anaconda3\\envs\\ju_hoon\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "C:\\Users\\or7l0\\anaconda3\\envs\\ju_hoon\\lib\\site-packages\\torch\\nn\\modules\\container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test = test_dataset.test_data.view(-1, 28 * 28).float().to('cuda:0')\n",
    "    Y_test = test_dataset.test_labels.to('cuda:0')\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(test_dataset) - 1)\n",
    "    X_single_data = test_dataset.test_data[r: r + 1].view(-1, 28 * 28).float().to('cuda:0')\n",
    "    Y_single_data = test_dataset.test_labels[r: r + 1].to('cuda:0')\n",
    "    \n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(test_dataset.test_data[r: r + 1].view(28, 28), cmap='Greys', \n",
    "              interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
